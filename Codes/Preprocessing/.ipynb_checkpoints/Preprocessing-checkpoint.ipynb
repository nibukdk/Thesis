{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline #This line helps to visaulize in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('Raw Data To Preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3323.22449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.479182</td>\n",
       "      <td>746.46501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2198.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2673.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3244.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3898.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>4817.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Years_of_Experience    Salaries\n",
       "count            42.000000    49.00000\n",
       "mean              5.000000  3323.22449\n",
       "std               2.479182   746.46501\n",
       "min               1.000000  2198.00000\n",
       "25%               3.000000  2673.00000\n",
       "50%               5.000000  3244.00000\n",
       "75%               7.000000  3898.00000\n",
       "max              10.000000  4817.00000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptoin might not be helpful since data is fake. \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 4 columns):\n",
      "Years_of_Experience    42 non-null float64\n",
      "Cities                 44 non-null object\n",
      "Salaries               49 non-null float64\n",
      "Gender                 2 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check information about null counts and datat types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Years_of_Experience     8\n",
       "Salaries                1\n",
       "Cities                  6\n",
       "Gender                 48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One way of Checking null values in dataframe\n",
    "df[['Years_of_Experience','Salaries', 'Cities','Gender']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visulaize the dataframe with df.null(), and display it in heatmap. By doing this it will only present two colors one for true and another for False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24027426208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another way to visualize null values in a dataframe. \n",
    "sns.heatmap(data=df.isnull(),annot=False, yticklabels=False, cmap='magma', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now since the Gender column is almost all empty lets also check the values in Gender column that are not null.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'M'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values in column \n",
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since, only available value is M and almost all values are missing, it seems appropraite to drop the whole column to avoid biasness of model.** In python **df.drop()** can be used to drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      "Years_of_Experience    42 non-null float64\n",
      "Cities                 44 non-null object\n",
      "Salaries               49 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# This confirms dropping of 'Gender' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets deal with other columns and their missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Imputer Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize our Imputer method with starategy 'mean' and missing_values to check as 'NAN'\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer takes numpy array with 2 dimensions as input. So, check type confirms it, but we have to reshape it from 1D to 2D as in line 20. Reshape can also be simply done by **your_arrary.reshape(-1,1) for 1D array**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[:,'Years_of_Experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[:,'Years_of_Experience'].values) #df.columns.values gives array but need to resahpe it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs_experience = df.loc[:,'Years_of_Experience'].values # Initialize and declare array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yrs_experience) # Its a one dimensional array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs_experience = yrs_experience.reshape(50,1) # Now we reshpe it to 2D. It can also be done as array.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yrs_experience) # This confirms our operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After creating our 2D array we fit our imputer to array and transform it\n",
    "imputer= imputer.fit_transform(yrs_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs_experience= imputer # Re-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Years_of_Experience']=yrs_experience # Re-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      "Years_of_Experience    50 non-null float64\n",
      "Cities                 44 non-null object\n",
      "Salaries               49 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Check the new status of 'Years of Experience' now the nan values are replaced with mean by imputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative For Imputer using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line replaces the NAN with mean values \n",
    "# Try by uncommenting it \n",
    "#df['Years_of_Experience'] = df['Years_of_Experience'].fillna(value=df['Years_of_Experience'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for the Cites column since its non-numeric lets use mode strategy. In statstics mode is most repating value in a list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it were continuous value then python package name **scipy** provides module name stats that gives several mathematical function like mode. But our column is categorical so we have to be creative. Pandas value_counts() can be handy at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rovaniemi    10\n",
       "Tampere       9\n",
       "Helsinki      9\n",
       "Name: Cities, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chech most repititive value using value_counts()\n",
    "#For us its 'Rovaniemi'\n",
    "df['Cities'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From our custome mode method we got value 'Rovaniemi' \n",
    "# We replace the cities empty value with 'Rovaniemi'\n",
    "df['Cities']=df['Cities'].fillna(value='Rovaniemi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for our salary column since missing value count is just one from (df.info()), we can either replace it with mean/median or just drop the row not column. The replacing part is similar process as above lets drop it for now. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Cities</th>\n",
       "      <th>Salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Oulu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Years_of_Experience Cities  Salaries\n",
       "35                  5.0   Oulu       NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we want to find position of NaN value in a column.\n",
    "df[df['Salaries'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above method is conditional operations popular is pandas. It gives the index of missing values since isna() provides true only for missing or NAN values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets drop the whole row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since our only NaN value is in Salry column. It only drops one row.\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      "Years_of_Experience    49 non-null float64\n",
      "Cities                 49 non-null object\n",
      "Salaries               49 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Now our data is free of missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we dropped one row we now have only 49 rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OneHotEncoder and LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import values of all the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like Imputer the input here is also array\n",
    "X = df.iloc[:,:].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Oulu', 'Tampere', 'Helsinki', 'Turku', 'Rovaniemi', 'Oulu',\n",
       "       'Rovaniemi', 'Helsinki', 'Turku', 'Rovaniemi'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the citys value\n",
    "X[0:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit, Tranform and Reassign our City column\n",
    "X[:,1] = cities_label_encoder.fit_transform(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 4, 2, 1, 2, 0, 4, 2], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This confirms our operation since the cities are changed to numeric values\n",
    "X[0:10,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, ML algorithm does not know our encoded labels are categorical changed to numerical basically a dummy variable, they can treat them as actual number. If that happens they might rate Turku higest with its value 4 and Helsinki lowest with its value 0. So, prevent that situation we use OneHotEncoder.\n",
    "OneHotEnoder creates one column for each encoded labels i.e one column for each city's encoded_label. Whats the key thing is since our categorical dummy's are like true and false rather than points, onehotencoder takes care of that by providing values to newly create columns of either 0 or 1. \n",
    "For example after OneHotEncoding, \n",
    "1. 'Oulu' value will be a coulmn with name '1'.\n",
    "2. All the rows before which have cities with values 'Oulu' will now have value of 1 as it emphasizes true\n",
    "3. All the rows before which did not have cities with values 'Oulu' will now have value of 0 as it emphasizes false.\n",
    "4. Same is the case for each cities in our case. For our df it will create 5 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(categorical_features=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=oneHotEncoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X) # 5 cities column and 2 other column 'Salaries' and 'Years_Of_Experience'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 4.000e+00,\n",
       "       4.607e+03])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1] # Format is not in float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative for Encoders Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy_Var_For__Oulu</th>\n",
       "      <th>Dummy_Var_For__Rovaniemi</th>\n",
       "      <th>Dummy_Var_For__Tampere</th>\n",
       "      <th>Dummy_Var_For__Turku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dummy_Var_For__Oulu  Dummy_Var_For__Rovaniemi  Dummy_Var_For__Tampere  \\\n",
       "0                    1                         0                       0   \n",
       "1                    0                         0                       1   \n",
       "2                    0                         0                       0   \n",
       "3                    0                         0                       0   \n",
       "4                    0                         1                       0   \n",
       "\n",
       "   Dummy_Var_For__Turku  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_var = pd.get_dummies(df['Cities'], prefix='Dummy_Var_For_',drop_first=True)\n",
    "dummy_var.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice something missing?** \n",
    "\n",
    "There is no dummy variable for city 'Helsinki'. It happend because of drop_first attribute in our get_dummies(). We do that to prevent our algorithm we are going to use in training to perfectly trace the pattern. If each cities are known and connected there algorithm will fit data perfectly in train but fail in test. See dummy variable trap articles for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE need to concat and make a df to split, scale and train,test(further processing)\n",
    "new_df = pd.concat(axis=1, objs=[df,dummy_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Cities</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Dummy_Var_For__Oulu</th>\n",
       "      <th>Dummy_Var_For__Rovaniemi</th>\n",
       "      <th>Dummy_Var_For__Tampere</th>\n",
       "      <th>Dummy_Var_For__Turku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Oulu</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Tampere</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years_of_Experience   Cities  Salaries  Dummy_Var_For__Oulu  \\\n",
       "0                  4.0     Oulu    4173.0                    1   \n",
       "1                  4.0  Tampere    4607.0                    0   \n",
       "\n",
       "   Dummy_Var_For__Rovaniemi  Dummy_Var_For__Tampere  Dummy_Var_For__Turku  \n",
       "0                         0                       0                     0  \n",
       "1                         0                       1                     0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since cities column is changed to dummies we don't need it anymore. \n",
    "# So,lets drp it\n",
    "new_df.drop(columns='Cities',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Dummy_Var_For__Oulu</th>\n",
       "      <th>Dummy_Var_For__Rovaniemi</th>\n",
       "      <th>Dummy_Var_For__Tampere</th>\n",
       "      <th>Dummy_Var_For__Turku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years_of_Experience  Salaries  Dummy_Var_For__Oulu  \\\n",
       "0                  4.0    4173.0                    1   \n",
       "1                  4.0    4607.0                    0   \n",
       "\n",
       "   Dummy_Var_For__Rovaniemi  Dummy_Var_For__Tampere  Dummy_Var_For__Turku  \n",
       "0                         0                       0                     0  \n",
       "1                         0                       1                     0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further Development is not because since our other linear and KNN files also has similar processes. **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
